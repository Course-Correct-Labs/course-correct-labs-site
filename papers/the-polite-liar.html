<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>The Polite Liar – Epistemic Pathology in Language Models | Course Correct Labs</title>
  <meta name="description" content="This paper looks at why large language models speak with confidence even when they have no access to the facts they present. The behavior is not a glitch. It is a structural outcome of how models are trained." />
  <link rel="canonical" href="https://coursecorrectlabs.com/papers/the-polite-liar" />
  <link rel="icon" type="image/png" href="../assets/images/favicon.png" />
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "The Polite Liar: Epistemic Pathology in Language Models",
    "author": {"@type": "Person", "name": "Bentley DeVilling"},
    "publisher": {"@type": "Organization", "name": "Course Correct Labs", "url": "https://coursecorrectlabs.com"},
    "url": "https://coursecorrectlabs.com/papers/the-polite-liar",
    "description": "This paper looks at why large language models speak with confidence even when they have no access to the facts they present."
  }
  </script>
  <style>
    :root{--bg:#000;--fg:#fff;--muted:rgba(255,255,255,.75);--blue:#3b82f6;--teal:#14b8a6;--orange:#FF6F00;--card:rgba(255,255,255,.06);--border:rgba(255,255,255,.12)}
    *{box-sizing:border-box}html{scroll-behavior:smooth}body{margin:0;font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;color:var(--fg);background:#000}a{text-decoration:none;color:var(--fg)}.container{max-width:1280px;margin:0 auto;padding:0 1.25rem}header{position:sticky;top:0;z-index:50;backdrop-filter:saturate(180%) blur(6px);background:rgba(0,0,0,.45)}.nav{height:64px;display:flex;align-items:center;justify-content:space-between}.brand{display:flex;align-items:center;gap:.65rem;font-weight:600;letter-spacing:.2px}.logo{height:48px;width:auto;display:block}.menu{display:none;gap:1rem;font-size:.95rem}.menu a{opacity:.8}.menu a.active{color:var(--blue);opacity:1}.hamburger{display:inline-flex;background:transparent;border:0;color:var(--fg);padding:.5rem;border-radius:.5rem}@media (min-width:768px){.menu{display:flex}.hamburger{display:none}}.mobile{display:none;border-top:1px solid var(--border);background:rgba(0,0,0,.7)}.mobile a{display:block;padding:.75rem 1rem;border-bottom:1px solid var(--border);opacity:.85}.hero{position:relative;padding:60px 0 40px;background:#000}h1,h2,h3{font-family:'Avenir Next',-apple-system,system-ui,sans-serif}.title-container{max-width:1100px;margin:0 auto}h1{font-size:28px;margin:0 0 1rem;line-height:1.2;text-align:center}section{padding:80px 0}.paper-hero{max-width:800px;margin:0 auto}.status-text{font-style:italic;font-size:.9rem;color:var(--muted);text-align:center;margin:0 0 2rem}.paper-img{width:100%;max-width:600px;aspect-ratio:1/1;border-radius:12px;background:#111318;object-fit:cover;display:block;margin:2rem auto}.author-note{font-style:italic;color:var(--muted);text-align:center;max-width:700px;margin:0 auto 3rem;font-size:1rem;line-height:1.7}.section-heading{text-transform:uppercase;font-size:1.02rem;font-weight:600;letter-spacing:.15em;color:var(--orange);margin:3rem 0 1rem;text-align:center}.content p{color:var(--muted);font-size:1rem;line-height:1.7;margin:1rem 0}.content ul{color:var(--muted);font-size:1rem;line-height:1.7;margin:1rem 0;padding-left:1.5rem}.content ul li{margin:.5rem 0}.links-text{color:var(--muted);margin:0;font-size:.95rem}footer{padding:48px 0;color:var(--muted);font-size:.95rem;text-align:center;background:#000}.footer-logo{height:64px;width:auto;margin:0 auto 24px;display:block;opacity:.8}.footer-links{display:flex;align-items:center;justify-content:center;gap:16px;flex-wrap:wrap;margin-bottom:16px}.footer-links a{display:inline-flex;align-items:center;justify-content:center;width:32px;height:32px;border-radius:50%;background:rgba(255,255,255,.08);transition:background .2s}.footer-links a:hover{background:rgba(255,255,255,.15)}.footer-links a svg{width:16px;height:16px;fill:currentColor}
  </style>
</head>
<body>
  <header>
    <div class="container nav">
      <a href="https://coursecorrectlabs.com" class="brand"><img src="../assets/images/logo.png" alt="Course Correct Labs" class="logo" /></a>
      <nav class="menu" id="menu">
        <a href="/research" class="active">Research</a>
        <a href="/studies">Studies</a>
        <a href="/evaluations">Evaluations</a>
        <a href="/partner-with-us">Partner With Us</a>
        <a href="/about">About</a>
        <a href="/contact">Contact</a>
      </nav>
      <button class="hamburger" id="hambtn">☰</button>
    </div>
    <div class="mobile" id="mobile">
      <div class="container">
        <a href="/research">Research</a><a href="/studies">Studies</a><a href="/evaluations">Evaluations</a><a href="/partner-with-us">Partner With Us</a><a href="/about">About</a><a href="/contact">Contact</a>
      </div>
    </div>
  </header>
  <main>
    <section class="hero">
      <div class="container paper-hero">
        <div class="title-container">
          <h1>The Polite Liar:<br>Epistemic Pathology in Language Models</h1>
        </div>
        <p class="status-text">Under review at AI and Society</p>
        <img class="paper-img" src="../assets/images/phi-research.png" alt="The Polite Liar visualization" loading="lazy" />

        <p class="author-note">This paper looks at why large language models speak with confidence even when they have no access to the facts they present. The behavior is not a glitch. It is a structural outcome of how models are trained.</p>

        <div class="content">
          <div class="section-heading">Summary</div>
          <p>This paper looks at why large language models speak with confidence even when they have no access to the facts they present. The behavior is not a glitch. It is a structural outcome of how models are trained. Reinforcement Learning from Human Feedback teaches systems to sound helpful, polished, and sincere. It does not teach them to track evidence. The result is a model that performs knowledge instead of holding it. It fabricates politely. It answers with certainty even when it has no way to know. The paper explains how this pattern emerges, why it persists across models and domains, and why it matters for any society that relies on systems whose confidence is manufactured rather than earned.</p>

          <div class="section-heading">Abstract</div>
          <p>Large language models exhibit a peculiar epistemic pathology: they speak as if they know, even when they do not. This paper argues that such confident fabrication—what I call the polite liar— is a structural consequence of reinforcement learning from human feedback (RLHF). Building on Frankfurt's analysis of bullshit as communicative indifference to truth, I show that this pathology is not deception but structural indifference: a reward architecture that optimizes for perceived sincerity over evidential accuracy. Current alignment methods reward models for being helpful, harmless, and polite, but not for being epistemically grounded. As a result, systems learn to maximize user satisfaction rather than truth, performing conversational fluency as a virtue. I analyze this behavior through the lenses of epistemic virtue theory, speech-act philosophy, and cognitive alignment, showing that RLHF produces agents trained to mimic epistemic confidence without access to epistemic justification. The polite liar thus reveals a deeper alignment tension between linguistic cooperation and epistemic integrity. The paper concludes with an "epistemic alignment" principle: reward justified confidence over perceived fluency.</p>

          <div class="section-heading">Why It Matters</div>
          <p>People read confidence as evidence. When a system expresses certainty, users infer reliability. A model trained to sound sure of itself becomes a source of misplaced trust. This is more than a technical flaw. It is a risk to the epistemic environment people depend on. When confident fabrication becomes normal, users cannot tell where the system has grounding and where it is guessing. Over time, this erodes the basic ability to judge when to trust a model and when to doubt it. The danger is quiet. The system does not lie to deceive. It lies because nothing in its training rewards the restraint that truth requires. The paper explains how this pattern forms, how to detect it, and how design choices can restore the distinction between knowing and sounding like one knows.</p>

          <div class="section-heading">Key Ideas</div>
          <ul>
            <li>RLHF rewards confidence and fluency, not evidence</li>
            <li>The model performs the act of knowing even when it lacks access to facts</li>
            <li>Polite fabrication is a structural outcome of the reward signal</li>
            <li>Users mistake conversational confidence for epistemic grounding</li>
            <li>Calibration does not solve the problem because confidence is hidden inside the model</li>
            <li>What matters is the assertive force expressed in language, not internal probabilities</li>
            <li>Epistemic alignment requires rewarding uncertainty, refusals, and humility</li>
            <li>A model must communicate limits, not just calculate them</li>
          </ul>

          <div style="text-align:center;margin-top:3rem">
            <a href="https://arxiv.org/abs/2511.07477" target="_blank" rel="noopener noreferrer" class="btn" style="display:inline-flex;align-items:center;gap:.5rem;padding:.7rem 1rem;border-radius:.6rem;border:1px solid var(--border);background:#111318;color:var(--fg);font-size:.9rem">arXiv →</a>
          </div>
        </div>
      </div>
    </section>
  </main>
  <footer>
    <div class="container">
      <img src="../assets/images/footer-logo.png" alt="Course Correct Labs" class="footer-logo" />
      <div class="footer-links">
        <a href="mailto:hello@coursecorrectlabs.com" aria-label="Email"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/></svg></a>
        <a href="https://github.com/Course-Correct-Labs" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg></a>
        <a href="https://x.com/coursecorrect" target="_blank" rel="noopener noreferrer" aria-label="X"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg></a>
        <a href="https://linkedin.com/company/course-correct-labs" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg></a>
      </div>
      <div>© <span id="yr"></span> Course Correct Labs</div>
    </div>
  </footer>
  <script>
    document.getElementById('yr').textContent=new Date().getFullYear();const hambtn=document.getElementById('hambtn');const mobile=document.getElementById('mobile');hambtn.addEventListener('click',()=>{const open=mobile.style.display==='block';mobile.style.display=open?'none':'block';hambtn.setAttribute('aria-expanded',open?'false':'true');});mobile.querySelectorAll('a').forEach(a=>a.addEventListener('click',()=>{mobile.style.display='none';hambtn.setAttribute('aria-expanded','false');}));
  </script>
</body>
</html>
