<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Recursive Confabulation – Why Reasoning Prompts Backfire | Course Correct Labs</title>
  <meta name="description" content="This study examines how models reuse their own fabrications as evidence, and why prompting them to 'reason' makes the problem worse." />
  <link rel="canonical" href="https://coursecorrectlabs.com/studies/recursive-confabulation" />
  <link rel="icon" type="image/png" href="../assets/images/favicon.png" />
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Recursive Confabulation: Why Reasoning Prompts Backfire and Grounding Works (Sometimes)",
    "author": {"@type": "Person", "name": "Bentley DeVilling"},
    "publisher": {"@type": "Organization", "name": "Course Correct Labs", "url": "https://coursecorrectlabs.com"},
    "url": "https://coursecorrectlabs.com/studies/recursive-confabulation",
    "description": "This study examines how models reuse their own fabrications as evidence, and why prompting them to 'reason' makes the problem worse."
  }
  </script>
  <style>
    :root{--bg:#000;--fg:#fff;--muted:rgba(255,255,255,.75);--blue:#3b82f6;--teal:#14b8a6;--orange:#FF6F00;--card:rgba(255,255,255,.06);--border:rgba(255,255,255,.12)}
    *{box-sizing:border-box}html{scroll-behavior:smooth}body{margin:0;font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;color:var(--fg);background:#000}a{text-decoration:none;color:var(--fg)}.container{max-width:1280px;margin:0 auto;padding:0 1.25rem}header{position:sticky;top:0;z-index:50;backdrop-filter:saturate(180%) blur(6px);background:rgba(0,0,0,.45)}.nav{height:64px;display:flex;align-items:center;justify-content:space-between}.brand{display:flex;align-items:center;gap:.65rem;font-weight:600;letter-spacing:.2px}.logo{height:48px;width:auto;display:block}.menu{display:none;gap:1rem;font-size:.95rem}.menu a{opacity:.8}.menu a.active{color:var(--blue);opacity:1}.hamburger{display:inline-flex;background:transparent;border:0;color:var(--fg);padding:.5rem;border-radius:.5rem}@media (min-width:768px){.menu{display:flex}.hamburger{display:none}}.mobile{display:none;border-top:1px solid var(--border);background:rgba(0,0,0,.7)}.mobile a{display:block;padding:.75rem 1rem;border-bottom:1px solid var(--border);opacity:.85}.hero{position:relative;padding:60px 0 40px;background:#000}h1,h2,h3{font-family:'Avenir Next',-apple-system,system-ui,sans-serif}.title-container{max-width:1100px;margin:0 auto}h1{font-size:28px;margin:0 0 1rem;line-height:1.2;text-align:center}section{padding:80px 0}.paper-hero{max-width:800px;margin:0 auto}.status-text{font-style:italic;font-size:.9rem;color:var(--muted);text-align:center;margin:0 0 2rem}.paper-img{width:100%;max-width:600px;aspect-ratio:1/1;border-radius:12px;background:#111318;object-fit:cover;display:block;margin:2rem auto}.author-note{font-style:italic;color:var(--muted);text-align:center;max-width:700px;margin:0 auto 3rem;font-size:1rem;line-height:1.7}.section-heading{text-transform:uppercase;font-size:1.02rem;font-weight:600;letter-spacing:.15em;color:var(--orange);margin:3rem 0 1rem;text-align:center}.content p{color:var(--muted);font-size:1rem;line-height:1.7;margin:1rem 0}.content ul{color:var(--muted);font-size:1rem;line-height:1.7;margin:1rem 0;padding-left:1.5rem}.content ul li{margin:.5rem 0}.links-text{color:var(--muted);margin:0;font-size:.95rem}footer{padding:48px 0;color:var(--muted);font-size:.95rem;text-align:center;background:#000}.footer-logo{height:64px;width:auto;margin:0 auto 24px;display:block;opacity:.8}.footer-links{display:flex;align-items:center;justify-content:center;gap:16px;flex-wrap:wrap;margin-bottom:16px}.footer-links a{display:inline-flex;align-items:center;justify-content:center;width:32px;height:32px;border-radius:50%;background:rgba(255,255,255,.08);transition:background .2s}.footer-links a:hover{background:rgba(255,255,255,.15)}.footer-links a svg{width:16px;height:16px;fill:currentColor}
  </style>
</head>
<body>
  <header>
    <div class="container nav">
      <a href="https://coursecorrectlabs.com" class="brand"><img src="../assets/images/logo.png" alt="Course Correct Labs" class="logo" /></a>
      <nav class="menu" id="menu">
        <a href="/research">Research</a>
        <a href="/studies" class="active">Studies</a>
        <a href="/evaluations">Evaluations</a>
        <a href="/partner-with-us">Partner With Us</a>
        <a href="/contact">Contact</a>
        <a href="/about">About</a>
      </nav>
      <button class="hamburger" id="hambtn">☰</button>
    </div>
    <div class="mobile" id="mobile">
      <div class="container">
        <a href="/research">Research</a><a href="/studies">Studies</a><a href="/evaluations">Evaluations</a><a href="/partner-with-us">Partner With Us</a>
        <a href="/contact">Contact</a>
        <a href="/about">About</a>
      </div>
    </div>
  </header>
  <main>
    <section class="hero">
      <div class="container paper-hero">
        <div class="title-container">
          <h1>Recursive Confabulation<br>Why Reasoning Prompts Backfire and Grounding Works (Sometimes)</h1>
        </div>
        <p class="status-text">Under review</p>
        <img class="paper-img" src="../assets/images/recursive-confabulation-studies-desktop.png" alt="Recursive Confabulation visualization" loading="lazy" />

        <div class="content">
          <div class="section-heading">Summary</div>
          <p>This study looks at why language models invent entities, believe their own inventions, and then defend them in later turns. The issue isn't single-turn hallucination. It is a multi-turn failure mode where the model reuses its own guesses as if they were facts. Once the false detail enters the conversation, it becomes part of the model's internal frame. The output feels more confident, not less.</p>
          <p>The paper tests 119 controlled conversations across three architectures and four interventions: baseline, fact tables, belief audits, and grounding. Reasoning prompts - the tools that are supposed to help models verify their claims - made the problem worse. They increased both persistence and correction latency. The only intervention that reliably reduced confabulation was grounding, and even that only worked for some models. Claude remained fully immune.</p>
          <p>The study shows that recursive confabulation is systematic. It is the natural result of models treating their own text as evidence. The pattern unfolds the same way across domains: early elaboration gives way to short, confident assertions that compress the fiction rather than expand it. This collapse of detail paired with rising certainty is the core signature of the phenomenon.</p>

          <div class="section-heading">Abstract</div>
          <p>Large language models routinely invent false entities, yet the internal mechanics of this process remain unclear. We define recursive confabulation as the self-reinforcing reuse of fabricated information within an ongoing dialogue. Across 119 controlled conversations with three frontier models (Claude 3.5 Haiku, GPT-4o Mini, Gemini 2.0 Flash) and four intervention arms (baseline, fact-table, belief-audit, grounding), we find a near-universal confabulation rate of 97%.</p>
          <p>Prompt-based safety interventions consistently failed. Fact-tables and belief-audits increased persistence by 24–31 percentage points relative to baseline (p < 0.05). By contrast, a grounding instruction requiring explicit source verification produced a statistically significant reduction in confabulation (100 → 70%, p = 0.0019, Cohen's h = 1.16), driven entirely by GPT-4o Mini (100 → 50%, p = 0.033); Gemini showed a nonsignificant trend (100 → 60%), while Claude 3.5 Haiku remained completely unaffected (100 → 100%).</p>
          <p>Qualitative analysis reveals that elaboration decreases rather than expands. Responses become shorter and less concrete while confidence remains high, a phenomenon we term semantic compression. Entity clustering exposes two overlapping error types: invention of nonexistent institutions and distortion of real ones. Together these results show that recursive confabulation is a systematic failure mode across current architectures, only partially mitigated by grounding and resistant in certain alignment regimes.</p>

          <div class="section-heading">Why It Matters</div>
          <p>A model that reuses its own fiction as evidence becomes harder to correct the longer the exchange continues. It forgets that it guessed. It treats its earlier invention as an established premise. This is the difference between one bad answer and a self-reinforcing false belief.</p>
          <p>The danger is not dramatic. It is procedural. Reasoning prompts - the methods people use to make models safer - actually strengthen the fabrication. They trigger justification rather than verification. The model supplies reasons for the false entity instead of checking whether it exists. Grounding helps, but only for models whose training makes verification meaningful. Others ignore the instruction entirely.</p>
          <p>This matters for any system where models read their own output or the output of other models. In multi-agent settings, recursive confabulation spreads. One model's guess becomes another model's assumption. Without architectural guardrails, small fictions turn into shared facts.</p>

          <div class="section-heading">Key Ideas</div>
          <ul>
            <li>A false statement in one turn becomes evidence in the next</li>
            <li>Reasoning prompts increase persistence by reinforcing the fiction</li>
            <li>Grounding helps only when the model treats verification as a real constraint</li>
            <li>Semantic compression replaces elaboration with short, confident assertions</li>
            <li>Models forget that they ever guessed and defend the invention as fact</li>
            <li>Cross-model propagation spreads confabulations across architectures</li>
            <li>Recursive confabulation is an architectural attractor, not an isolated mistake</li>
            <li>Fixing it requires mechanisms that distinguish generated text from verified information</li>
          </ul>

          <div style="text-align:center;margin-top:3rem">
            <a href="https://colab.research.google.com/github/Course-Correct-Labs/recursive-confabulation/blob/main/notebooks/RC_reproduction.ipynb" target="_blank" rel="noopener noreferrer" class="btn" style="display:inline-flex;align-items:center;gap:.5rem;padding:.7rem 1rem;border-radius:.6rem;border:1px solid var(--border);background:#111318;color:var(--fg);font-size:.9rem;margin-right:.5rem">Open Colab →</a>
            <a href="https://github.com/Course-Correct-Labs/recursive-confabulation" target="_blank" rel="noopener noreferrer" class="btn" style="display:inline-flex;align-items:center;gap:.5rem;padding:.7rem 1rem;border-radius:.6rem;border:1px solid var(--border);background:#111318;color:var(--fg);font-size:.9rem">GitHub →</a>
          </div>
        </div>
      </div>
    </section>
  </main>
  <footer>
    <div class="container">
      <img src="../assets/images/footer-logo.png" alt="Course Correct Labs" class="footer-logo" />
      <div class="footer-links">
        <a href="mailto:hello@coursecorrectlabs.com" aria-label="Email"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/></svg></a>
        <a href="https://github.com/Course-Correct-Labs" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg></a>
        <a href="https://x.com/CourseCorrectAI" target="_blank" rel="noopener noreferrer" aria-label="X"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg></a>
        <a href="https://linkedin.com/company/course-correct-labs" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg></a>
      </div>
      <div>© <span id="yr"></span> Course Correct Labs</div>
    </div>
  </footer>
  <script>
    document.getElementById('yr').textContent=new Date().getFullYear();const hambtn=document.getElementById('hambtn');const mobile=document.getElementById('mobile');hambtn.addEventListener('click',()=>{const open=mobile.style.display==='block';mobile.style.display=open?'none':'block';hambtn.setAttribute('aria-expanded',open?'false':'true');});mobile.querySelectorAll('a').forEach(a=>a.addEventListener('click',()=>{mobile.style.display='none';hambtn.setAttribute('aria-expanded','false');}));
  </script>
</body>
</html>
